{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from scipy.sparse import csr_matrix, vstack\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Custom modules\n",
    "import const\n",
    "import func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_numeric', 'train_categorical_to_num', 'train_date']\n"
     ]
    }
   ],
   "source": [
    "print const.TRAIN_FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "      <th>station</th>\n",
       "      <th>feature_nr</th>\n",
       "      <th>feat_nr_dat</th>\n",
       "      <th>name_dat</th>\n",
       "      <th>name_cat</th>\n",
       "      <th>name_num</th>\n",
       "      <th>col_dat</th>\n",
       "      <th>col_num</th>\n",
       "      <th>col_cat</th>\n",
       "      <th>station_V2</th>\n",
       "      <th>line_V2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>L0_S0_D1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L0_S0_F0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>L0_S0_D3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L0_S0_F2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>L0_S0_D5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L0_S0_F4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   line  station  feature_nr  feat_nr_dat  name_dat name_cat  name_num  \\\n",
       "0     0        0           0          1.0  L0_S0_D1      NaN  L0_S0_F0   \n",
       "1     0        0           2          3.0  L0_S0_D3      NaN  L0_S0_F2   \n",
       "2     0        0           4          5.0  L0_S0_D5      NaN  L0_S0_F4   \n",
       "\n",
       "   col_dat  col_num  col_cat  station_V2  line_V2  \n",
       "0      0.0      0.0      NaN         0.0      1.0  \n",
       "1      1.0      1.0      NaN         0.0      1.0  \n",
       "2      2.0      2.0      NaN         0.0      1.0  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lut = pd.read_csv(const.LOOK_UP_TABLE)\n",
    "lut.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning <open file '/Volumes/My Book/kaggle_bosch/train_date.pkl', mode 'rb' at 0x115eba540>.pkl\n",
      "Returning <open file '/Volumes/My Book/kaggle_bosch/test_date.pkl', mode 'rb' at 0x115eba540>.pkl\n"
     ]
    }
   ],
   "source": [
    "dat = func.load_data_file(const.TRAIN_FILES[2])\n",
    "dat_train = dat['data']['features']\n",
    "id_train = dat['data']['ids']\n",
    "\n",
    "dat = func.load_data_file(const.TEST_FILES[2])\n",
    "\n",
    "dat_data = vstack([dat_train, dat['data']['features']], format='csr')\n",
    "ids = pd.concat([id_train, dat['data']['ids']], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2367495, 1156)\n",
      "(2367495, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id\n",
       "0   4\n",
       "1   6\n",
       "2   7"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print dat_data.shape\n",
    "print ids.shape\n",
    "ids.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>L0_S0_D1</th>\n",
       "      <th>L0_S0_D3</th>\n",
       "      <th>L0_S0_D5</th>\n",
       "      <th>L0_S0_D7</th>\n",
       "      <th>L0_S0_D9</th>\n",
       "      <th>L0_S0_D11</th>\n",
       "      <th>L0_S0_D13</th>\n",
       "      <th>L0_S0_D15</th>\n",
       "      <th>L0_S0_D17</th>\n",
       "      <th>...</th>\n",
       "      <th>L3_S50_D4246</th>\n",
       "      <th>L3_S50_D4248</th>\n",
       "      <th>L3_S50_D4250</th>\n",
       "      <th>L3_S50_D4252</th>\n",
       "      <th>L3_S50_D4254</th>\n",
       "      <th>L3_S51_D4255</th>\n",
       "      <th>L3_S51_D4257</th>\n",
       "      <th>L3_S51_D4259</th>\n",
       "      <th>L3_S51_D4261</th>\n",
       "      <th>L3_S51_D4263</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>82.24</td>\n",
       "      <td>82.24</td>\n",
       "      <td>82.24</td>\n",
       "      <td>82.24</td>\n",
       "      <td>82.24</td>\n",
       "      <td>82.24</td>\n",
       "      <td>82.24</td>\n",
       "      <td>82.24</td>\n",
       "      <td>82.24</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>1618.70</td>\n",
       "      <td>1618.70</td>\n",
       "      <td>1618.70</td>\n",
       "      <td>1618.70</td>\n",
       "      <td>1618.70</td>\n",
       "      <td>1618.70</td>\n",
       "      <td>1618.70</td>\n",
       "      <td>1618.70</td>\n",
       "      <td>1618.70</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 1157 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  L0_S0_D1  L0_S0_D3  L0_S0_D5  L0_S0_D7  L0_S0_D9  L0_S0_D11  L0_S0_D13  \\\n",
       "0   4     82.24     82.24     82.24     82.24     82.24      82.24      82.24   \n",
       "1   6       NaN       NaN       NaN       NaN       NaN        NaN        NaN   \n",
       "2   7   1618.70   1618.70   1618.70   1618.70   1618.70    1618.70    1618.70   \n",
       "\n",
       "   L0_S0_D15  L0_S0_D17      ...       L3_S50_D4246  L3_S50_D4248  \\\n",
       "0      82.24      82.24      ...                NaN           NaN   \n",
       "1        NaN        NaN      ...                NaN           NaN   \n",
       "2    1618.70    1618.70      ...                NaN           NaN   \n",
       "\n",
       "   L3_S50_D4250  L3_S50_D4252  L3_S50_D4254  L3_S51_D4255  L3_S51_D4257  \\\n",
       "0           NaN           NaN           NaN           NaN           NaN   \n",
       "1           NaN           NaN           NaN           NaN           NaN   \n",
       "2           NaN           NaN           NaN           NaN           NaN   \n",
       "\n",
       "   L3_S51_D4259  L3_S51_D4261  L3_S51_D4263  \n",
       "0           NaN           NaN           NaN  \n",
       "1           NaN           NaN           NaN  \n",
       "2           NaN           NaN           NaN  \n",
       "\n",
       "[3 rows x 1157 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_our = pd.read_csv(os.path.join(const.BASE_PATH, const.TRAIN_FILES[2] + '.csv'), nrows=1000)\n",
    "dat_our.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load jayjay's features\n",
    "#dat_jay = pd.read_csv('data_jayjay/train.csv', nrows=1000)\n",
    "dat_jay = pd.read_csv('data_jayjay/train.csv')\n",
    "#cat_cols = cat_jay.filter(like='CATEGORICAL').columns\n",
    "#cat_jay = cat_jay[cat_cols]\n",
    "#print cat_jay.shape\n",
    "#cat_jay.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.46731303101e-14\n",
      "1\n",
      "1\n",
      "5.62173829899e-11\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# On all samples\n",
    "print (dat_our.iloc[:,1:].kurtosis(axis=1)-dat_jay['Kurtosis']).mean()\n",
    "print (dat_our.iloc[:,1:].max(axis=1)!=dat_jay['Max']).sum() # Nans are different\n",
    "print (dat_our.iloc[:,1:].min(axis=1)!=dat_jay['Min']).sum() # Nans are different\n",
    "print (dat_our.iloc[:,1:].mean(axis=1)-dat_jay['Mean']).mean()\n",
    "print (dat_our.iloc[:,1:].apply(lambda x: x.nunique(), axis=1)!=dat_jay['Unique count']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=pd.Series([1,np.nan,2])\n",
    "b=pd.Series([1,np.nan,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare(x,y):\n",
    "    if x.equals(y):\n",
    "        return True\n",
    "    else:\n",
    "        return 'Different: mean: {} sum: {}'.format((x-y).mean(), (x-y).sum())\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 0\n",
      "True\n",
      "True\n",
      "8.2864247259e-11\n",
      "-1.4875440359e-14\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Lines 0\n",
    "line=0\n",
    "col_date = lut[lut['line']==line].col_dat.values\n",
    "col_date = [int(i)+1 for i in col_date if not np.isnan(i)]\n",
    "\n",
    "print('Line 0')\n",
    "print compare(dat_our.iloc[:,col_date].max(axis=1), dat_jay['L0_Max']) # Nans are different\n",
    "print compare(dat_our.iloc[:,col_date].min(axis=1), dat_jay['L0_Min']) # Nans are different\n",
    "print compare(dat_our.iloc[:,col_date].mean(axis=1), dat_jay['L0_Mean'])\n",
    "print compare(dat_our.iloc[:,col_date].max(axis=1) - dat_our.iloc[:,col_date].min(axis=1), dat_jay['L0_Range'])\n",
    "print compare(dat_our.iloc[:,col_date].apply(lambda x: x.nunique(), axis=1), dat_jay['L0_Unique count'])\n",
    "print compare(dat_our.iloc[:,col_date].max(axis=1), dat_jay['DATE_L0max']) # Nans are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lines 1\n",
    "line=1\n",
    "col_date = lut[lut['line']==line].col_dat.values\n",
    "col_date = [int(i)+1 for i in col_date if not np.isnan(i)]\n",
    "\n",
    "print('Line 1')\n",
    "print compare(dat_our.iloc[:,col_date].max(axis=1), dat_jay['L1_Max']) # Nans are different\n",
    "print compare(dat_our.iloc[:,col_date].min(axis=1), dat_jay['L1_Min']) # Nans are different\n",
    "print compare(dat_our.iloc[:,col_date].max(axis=1) - dat_our.iloc[:,col_date].min(axis=1), dat_jay['L1_Range'])\n",
    "print compare(dat_our.iloc[:,col_date].apply(lambda x: x.nunique(), axis=1), dat_jay['L1_Unique count'])\n",
    "print compare(dat_our.iloc[:,col_date].kurtosis(axis=1), dat_jay['DATE_L1kurt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 2\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Lines 2\n",
    "line=2\n",
    "col_date = lut[lut['line']==line].col_dat.values\n",
    "col_date = [int(i)+1 for i in col_date if not np.isnan(i)]\n",
    "\n",
    "print('Line 2')\n",
    "print compare(dat_our.iloc[:,col_date].max(axis=1), dat_jay['L2_Max']) # Nans are different\n",
    "print compare(dat_our.iloc[:,col_date].min(axis=1), dat_jay['L2_Min']) # Nans are different\n",
    "print compare(dat_our.iloc[:,col_date].max(axis=1) - dat_our.iloc[:,col_date].min(axis=1), dat_jay['L2_Range'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 3\n",
      "True\n",
      "True\n",
      "-1.23021153797e-14\n",
      "True\n",
      "-1.89971991518e-13\n"
     ]
    }
   ],
   "source": [
    "# Lines 3\n",
    "line=3\n",
    "col_date = lut[lut['line']==line].col_dat.values\n",
    "col_date = [int(i)+1 for i in col_date if not np.isnan(i)]\n",
    "\n",
    "print('Line 3')\n",
    "print compare(dat_our.iloc[:,col_date].max(axis=1), dat_jay['L3_Max']) \n",
    "print compare(dat_our.iloc[:,col_date].min(axis=1), dat_jay['L3_Min']) \n",
    "print compare(dat_our.iloc[:,col_date].max(axis=1) - dat_our.iloc[:,col_date].min(axis=1), dat_jay['L3_Range'])\n",
    "print compare(dat_our.iloc[:,col_date].apply(lambda x: x.nunique(), axis=1), dat_jay['L3_Unique count'])\n",
    "print compare(dat_our.iloc[:,col_date].kurtosis(axis=1), dat_jay['DATE_L3kurt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 3\n",
      "-1.01295843022e-17\n",
      "-5.11415987649e-16\n",
      "2.70646024476e-15\n",
      "2.45490308551e-16\n",
      "-8.93419814403e-15\n",
      "1.38480289532e-15\n"
     ]
    }
   ],
   "source": [
    "# Between lines and stations\n",
    "col_dateL0 = [int(i)+1 for i in lut[lut['line']==0].col_dat.values if not np.isnan(i)]\n",
    "col_dateL2 = [int(i)+1 for i in lut[lut['line']==2].col_dat.values if not np.isnan(i)]\n",
    "col_dateL3 = [int(i)+1 for i in lut[lut['line']==3].col_dat.values if not np.isnan(i)]\n",
    "col_dateS37 = [int(i)+1 for i in lut[lut['station']==37].col_dat.values if not np.isnan(i)]\n",
    "col_dateS26 = [int(i)+1 for i in lut[lut['station']==26].col_dat.values if not np.isnan(i)]\n",
    "col_dateS30 = [int(i)+1 for i in lut[lut['station']==30].col_dat.values if not np.isnan(i)]\n",
    "col_dateS34 = [int(i)+1 for i in lut[lut['station']==34].col_dat.values if not np.isnan(i)]\n",
    "\n",
    "print('Line 3')\n",
    "print compare(dat_our.iloc[:,col_dateL0].max(axis=1) - dat_our.iloc[:,col_dateL3].max(axis=1), dat_jay['L0max_L3max'])\n",
    "print compare(dat_our.iloc[:,col_dateL2].max(axis=1) - dat_our.iloc[:,col_dateS37].max(axis=1), dat_jay['L2max_S37max'])\n",
    "print compare(dat_our.iloc[:,col_dateL3].max(axis=1) - dat_our.iloc[:,col_dateL0].min(axis=1), dat_jay['L3max_L0min'])\n",
    "print compare(dat_our.iloc[:,col_dateL3].max(axis=1) - dat_our.iloc[:,col_dateS26].max(axis=1), dat_jay['L3max_S26max'])\n",
    "print compare(dat_our.iloc[:,col_dateL3].max(axis=1) - dat_our.iloc[:,col_dateS30].max(axis=1), dat_jay['L3max_S30max'])\n",
    "print compare(dat_our.iloc[:,col_dateL3].max(axis=1) - dat_our.iloc[:,col_dateS34].min(axis=1), dat_jay['L3max_S34min'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1156"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(col_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Same station\n",
    "\n",
    "# First get max per line for all train and test samples\n",
    "df = pd.DataFrame(columns=['L0max','L1max','L2max','L3max'], index=ids.Id)\n",
    "for l in range(4):\n",
    "    col_date = [int(i) for i in lut[lut['line']==l].col_dat.values if not np.isnan(i)]\n",
    "\n",
    "    df['L{}max'.format(l)] = dat_data[:, col_date].max(1).todense().A1\n",
    "    \n",
    "    df['L{}max'.format(l)].replace(0, np.nan, inplace=True)\n",
    "    df['L{}max'.format(l)].round(2)\n",
    "\n",
    "# To go row index to check sorting afterwards\n",
    "df.reset_index(inplace=True)\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sort by ID\n",
    "df.sort_values(['Id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    df[col + '_prev'] = df[col].shift(1)\n",
    "    df[col + '_next'] = df[col].shift(-1)\n",
    "\n",
    "# Use only train id\n",
    "df = df[df['Id'].isin(id_train.Id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Id</th>\n",
       "      <th>L0max</th>\n",
       "      <th>L1max</th>\n",
       "      <th>L2max</th>\n",
       "      <th>L3max</th>\n",
       "      <th>index_prev</th>\n",
       "      <th>index_next</th>\n",
       "      <th>Id_prev</th>\n",
       "      <th>Id_next</th>\n",
       "      <th>L0max_prev</th>\n",
       "      <th>L0max_next</th>\n",
       "      <th>L1max_prev</th>\n",
       "      <th>L1max_next</th>\n",
       "      <th>L2max_prev</th>\n",
       "      <th>L2max_next</th>\n",
       "      <th>L3max_prev</th>\n",
       "      <th>L3max_next</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>82.269997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87.290001</td>\n",
       "      <td>1183749.0</td>\n",
       "      <td>1183750.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>255.490005</td>\n",
       "      <td>671.950012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>704.109985</td>\n",
       "      <td>255.500000</td>\n",
       "      <td>711.080017</td>\n",
       "      <td>256.279999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1313.150024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1315.750000</td>\n",
       "      <td>1183750.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>255.490005</td>\n",
       "      <td>1618.729980</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>255.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256.279999</td>\n",
       "      <td>1624.420044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1618.729980</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1624.420044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1183751.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1313.150024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>743.400024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>760.929993</td>\n",
       "      <td>1315.750000</td>\n",
       "      <td>770.280029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1149.219971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1154.160034</td>\n",
       "      <td>1183751.0</td>\n",
       "      <td>1183752.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>907.369995</td>\n",
       "      <td>743.400024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>760.929993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>770.280029</td>\n",
       "      <td>911.289978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>602.669983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>606.020020</td>\n",
       "      <td>1183752.0</td>\n",
       "      <td>1183753.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>907.369995</td>\n",
       "      <td>602.669983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>911.289978</td>\n",
       "      <td>623.280029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Id        L0max  L1max  L2max        L3max  index_prev  index_next  \\\n",
       "0      0   4    82.269997    NaN    NaN    87.290001   1183749.0   1183750.0   \n",
       "1      1   6  1313.150024    NaN    NaN  1315.750000   1183750.0         2.0   \n",
       "2      2   7  1618.729980    NaN    NaN  1624.420044         1.0   1183751.0   \n",
       "3      3   9  1149.219971    NaN    NaN  1154.160034   1183751.0   1183752.0   \n",
       "4      4  11   602.669983    NaN    NaN   606.020020   1183752.0   1183753.0   \n",
       "\n",
       "   Id_prev  Id_next   L0max_prev   L0max_next  L1max_prev  L1max_next  \\\n",
       "0      3.0      5.0          NaN   255.490005  671.950012         NaN   \n",
       "1      5.0      7.0   255.490005  1618.729980         NaN         NaN   \n",
       "2      6.0      8.0  1313.150024          NaN         NaN  743.400024   \n",
       "3      8.0     10.0          NaN   907.369995  743.400024         NaN   \n",
       "4     10.0     12.0   907.369995   602.669983         NaN         NaN   \n",
       "\n",
       "   L2max_prev  L2max_next   L3max_prev   L3max_next  \n",
       "0  704.109985  255.500000   711.080017   256.279999  \n",
       "1  255.500000         NaN   256.279999  1624.420044  \n",
       "2         NaN  760.929993  1315.750000   770.280029  \n",
       "3  760.929993         NaN   770.280029   911.289978  \n",
       "4         NaN         NaN   911.289978   623.280029  "
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 0\n",
      "True\n",
      "True\n",
      "Line 1\n",
      "True\n",
      "True\n",
      "Line 2\n",
      "True\n",
      "True\n",
      "Line 3\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Now compare\n",
    "print('Line 0')\n",
    "print compare(((df['L0max']==df['L0max_prev']) | (df['L0max'].isnull()) & (df['L0max_prev'].isnull())).astype(int), \n",
    "              dat_jay['sameL0'])\n",
    "print compare(((df['L0max']==df['L0max_next']) | (df['L0max'].isnull()) & (df['L0max_next'].isnull())).astype(int), \n",
    "              dat_jay['sameL0 (#1)'])\n",
    "print('Line 1')\n",
    "print compare(((df['L1max']==df['L1max_prev']) | (df['L1max'].isnull()) & (df['L1max_prev'].isnull())).astype(int), \n",
    "              dat_jay['sameL1'])\n",
    "print compare(((df['L1max']==df['L1max_next']) | (df['L1max'].isnull()) & (df['L1max_next'].isnull())).astype(int), \n",
    "              dat_jay['sameL1 (#1)'])\n",
    "print('Line 2')\n",
    "print compare(((df['L2max']==df['L2max_prev']) | (df['L2max'].isnull()) & (df['L2max_prev'].isnull())).astype(int), \n",
    "              dat_jay['sameL2'])\n",
    "print compare(((df['L2max']==df['L2max_next']) | (df['L2max'].isnull()) & (df['L2max_next'].isnull())).astype(int), \n",
    "              dat_jay['sameL2 (#1)'])\n",
    "print('Line 3')\n",
    "print compare(((df['L3max']==df['L3max_prev']) | (df['L3max'].isnull()) & (df['L3max_prev'].isnull())).astype(int), \n",
    "              dat_jay['sameL3'])\n",
    "print compare(((df['L3max']==df['L3max_next']) | (df['L3max'].isnull()) & (df['L3max_next'].isnull())).astype(int), \n",
    "              dat_jay['sameL3 (#1)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_cols = ['Kurtosis', 'Max', 'Mean', 'Min', 'Range','Unique count',\n",
    "             'L0_Max', 'L0_Mean', 'L0_Min', 'L0_Range', 'L0_Unique count', 'DATE_L0max',\n",
    "             'L1_Max', 'L1_Min', 'L1_Range', 'L1_Unique count', 'DATE_L1kurt',\n",
    "             'L2_Max', 'L2_Min', 'L2_Range', \n",
    "             'L3_Max', 'L3_Min', 'L3_Range', 'L3_Unique count', 'DATE_L3kurt', 'DATE_L3min',\n",
    "             'L0max_L3max', 'L2max_S37max', 'L3max_L0min', 'L3max_S26max', 'L3max_S30max', 'L3max_S34min',\n",
    "             'sameL0', 'sameL0 (#1)', 'sameL1', 'sameL1 (#1)', 'sameL2', 'sameL2 (#1)', 'sameL3', 'sameL3 (#1)',\n",
    "'L1_L1_Missing value count',\n",
    "'L3_L3_Missing value count',\n",
    "'L3_L3_Unique count',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jay_feat_diffs = ['S13min_S33min',\n",
    "'S22max_S32min',\n",
    "'S22min_S32min',\n",
    "'S26min_S24min',\n",
    "'S26min_S37min',\n",
    "'S27min_S32min',\n",
    "'S29max_S35max',\n",
    "'S29min_S32min',\n",
    "'S29min_S34min',\n",
    "'S29min_S37min',\n",
    "'S30min_S35min',\n",
    "'S30min_S37min',\n",
    "'S32max_S37min',\n",
    "'S32min_S10min',\n",
    "'S32min_S30min',\n",
    "'S32min_S34min',\n",
    "'S33max_S29min',\n",
    "'S33min_S30min',\n",
    "'S33min_S34min',\n",
    "'S33min_S35min',\n",
    "'S33min_S36min',\n",
    "'S33min_S37min',\n",
    "'S34min_S35min',\n",
    "'S35min_L1min',\n",
    "'S36max_S29min',\n",
    "'S37min_S34min']\n",
    "jay_feat_dates = [\n",
    "'DATE_S0_max',\n",
    "'DATE_S1_max',\n",
    "'DATE_S10max',\n",
    "'DATE_S10min',\n",
    "'DATE_S11max',\n",
    "'DATE_S13max',\n",
    "'DATE_S13min',\n",
    "'DATE_S18max',\n",
    "'DATE_S19max',\n",
    "'DATE_S2_max',\n",
    "'DATE_S20max',\n",
    "'DATE_S20min',\n",
    "'DATE_S21max',\n",
    "'DATE_S21min',\n",
    "'DATE_S23max',\n",
    "'DATE_S24max',\n",
    "'DATE_S24min',\n",
    "'DATE_S25max',\n",
    "'DATE_S25min',\n",
    "'DATE_S26max',\n",
    "'DATE_S27max',\n",
    "'DATE_S28max',\n",
    "'DATE_S3_max',\n",
    "'DATE_S30max',\n",
    "'DATE_S32max',\n",
    "'DATE_S32min',\n",
    "'DATE_S33max',\n",
    "'DATE_S34max',\n",
    "'DATE_S35max',\n",
    "'DATE_S36max',\n",
    "'DATE_S37max',\n",
    "'DATE_S38max',\n",
    "'DATE_S4_max',\n",
    "'DATE_S40max',\n",
    "'DATE_S43max',\n",
    "'DATE_S44max',\n",
    "'DATE_S45min',\n",
    "'DATE_S47max',\n",
    "'DATE_S49max',\n",
    "'DATE_S50max',\n",
    "'DATE_S6_max',\n",
    "'DATE_S7_max',\n",
    "'DATE_S8_max',\n",
    "'DATE_S8_min',\n",
    "'DATE_S9_max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'L0_Max', u'L3_Max', u'L1_Max', u'L2_Max', u'Max',\n",
       "       u'CATEGORICAL_Max______1', u'CATEGORICAL_Max______3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_jay.filter(like='Max').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Id', u'Response', u'ratio', u'FOR100_Sum', u'L3_S33_F3857',\n",
       "       u'FOR165_Sum', u'BAC165_Sum', u'BAC100_Sum', u'sameL0 (#1)',\n",
       "       u'L3_S30_F3754', u'L3_S30_F3809', u'FOR165_log_lag_L2', u'L3_S30_F3744',\n",
       "       u'BAC100_log_lag_L3', u'DATE_L3kurt', u'sameL3', u'sameL3 (#1)',\n",
       "       u'FOR100_log_lag_L3', u'FOR165_log_lag', u'BAC165_log_lag',\n",
       "       u'L3_S30_F3774', u'sameL1 (#1)', u'L3_S33_F3859', u'L3_S30_F3494',\n",
       "       u'L3_S29_F3333', u'BAC165_log_lag_L3', u'L3_S30_F3759', u'L0_S1_F28',\n",
       "       u'L3_S29_F3373', u'Range', u'Kurtosis', u'L3_S33_F3865', u'BAC30_Sum_S',\n",
       "       u'DATE_S33max', u'FOR165_log_lag_L3', u'FOR60_Sum_S3', u'L3_S29_F3348',\n",
       "       u'sameL2 (#1)', u'L0_Max', u'L3_S30_F3769', u'Response(-1)',\n",
       "       u'L3_S30_F3749', u'BAC100_log_lag', u'L3_S29_F3351', u'L3_S36_F3920',\n",
       "       u'FOR100_log_lag', u'BAC165_log_lag_L2', u'BAC60_Sum_S3',\n",
       "       u'L3_S29_F3339', u'L3_S30_F3804', u'L3max_L0min', u'L3_S29_F3379',\n",
       "       u'L3_S29_F3479', u'FOR100_log_lag_L2', u'BAC165_log_lag_L1',\n",
       "       u'BAC165_log_lag_L0', u'FOR30_Sum_S', u'BAC100_log_lag_L2',\n",
       "       u'L3_S29_F3342', u'L3_S29_F3327', u'L0_S2_F44', u'L3_S30_F3604',\n",
       "       u'L0_S3_F100', u'L3_S30_F3534', u'L3_S29_F3354', u'L3_S30_F3574',\n",
       "       u'L1_S24_F1844', u'L0_S0_F20_*_L0_S0_F20', u'L3_S30_F3639',\n",
       "       u'FOR165_log_lag_L1', u'FOR100_log_lag_L1', u'FOR165_log_lag_L0',\n",
       "       u'L3_S30_F3504', u'L3_S30_F3609', u'L0_S7_F138', u'L3_S29_F3321',\n",
       "       u'L3_Min', u'L3_S29_F3336', u'Response(-1) (#1)', u'L0max_L3max',\n",
       "       u'BAC100_log_lag_L1', u'L3_S30_F3709', u'L3_S30_F3829',\n",
       "       u'FOR60_log_lag_S33', u'L3_S29_F3315', u'L0_S0_F18', u'L3_S30_F3544',\n",
       "       u'L3_S29_F3330', u'L0_S1_F24', u'L0_S5_F116', u'L3_S29_F3324',\n",
       "       u'CATEGORICAL_Last_____1', u'FOR60_log_lag_S30', u'L0_S0_F0',\n",
       "       u'L0_S4_F109', u'L0_S9_F180', u'L3_S35_F3889', u'L1_S24_F1581',\n",
       "       u'CATEGORICAL_out_out_L3_S32_F3854_class2', u'L2_Min'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_jay.columns[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce JayJay's features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jay_means = cat_jay.mean()\n",
    "jay_sums = cat_jay.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def value_last_element_row(X):\n",
    "    ''' Return last value of each row of sparse csr matrix X'''\n",
    "    \n",
    "    # Get element where new row starts -1\n",
    "    last = X.indptr[1:] - 1\n",
    "    \n",
    "    output = X.data[last]\n",
    "    \n",
    "    # Replace row with zero non-zero elements by nan\n",
    "    output[np.diff(X.indptr)==0] = np.nan\n",
    "    \n",
    "    return output\n",
    "\n",
    "def max_element_row(X):\n",
    "    ''' Return maximum value of each row of sparse csr matrix X'''\n",
    "    ''' nan values are assumed to be encoded as zero'''\n",
    "    \n",
    "    output = X.max(1).todense().A1\n",
    "    \n",
    "    output[output==0] = np.nan\n",
    "    \n",
    "    return output\n",
    "\n",
    "def alpha_num_max_element_row(X):\n",
    "    ''' Return alpha num maximum value of each row of sparse csr matrix X'''\n",
    "    ''' nan values are assumed to be encoded as zero'''\n",
    "    ''' Lazy, slow implementation, via data/indtptr much faster'''\n",
    "    \n",
    "    output= []\n",
    "    \n",
    "    for n in range(X.shape[0]):\n",
    "        nz = X[n,:].nonzero()[1]\n",
    "        \n",
    "        if nz.shape[0]>0:\n",
    "            data = ['{:d}'.format(int(x)) for x in set(X[n, nz].todense().A1)]\n",
    "            output.append( int(float(max(data))))\n",
    "        else:\n",
    "            #output.append(np.nan)\n",
    "            output.append(0)\n",
    "    \n",
    "    return output\n",
    "\n",
    "def nunique_row(X):\n",
    "    ''' Return number of unique per row'''\n",
    "    ''' Lazy, slow implementation, via data/indtptr much faster'''\n",
    "    \n",
    "    output= []\n",
    "    \n",
    "    for n in range(X.shape[0]):\n",
    "        nz = X[n,:].nonzero()[1]\n",
    "        \n",
    "        if nz.shape[0]>0:\n",
    "            output.append( len(set(X[n, nz].todense().A1)))\n",
    "        else:\n",
    "            output.append(0)\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0041672756087238238"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CATEGORICAL_Last_____1\n",
    "n_last = cat_data[n,:].nonzero()[1][-1]\n",
    "sum([2, 4, 514] == cat_data[n, n_last])\n",
    "pd.Series(value_last_element_row(cat_data)).isin([2, 4, 514]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0034889211968435821"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CATEGORICAL_Last_____2\n",
    "pd.Series(value_last_element_row(cat_data)).isin([16, 48]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2082.8501723763607"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## CATEGORICAL_Missing value count\n",
    "pd.Series(cat_data.shape[1] - np.diff(cat_data.indptr)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0027488982020651372"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CATEGORICAL_Max______1 (takes a while)\n",
    "list1 = [2, 8389632, 514]\n",
    "pd.Series(alpha_num_max_element_row(cat_data)).isin(list1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30736635446594585"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CATEGORICAL_Max______3 (takes a while)\n",
    "list3 = [3, 145, 4, 143, 8, 512, 6, 32]\n",
    "pd.Series(alpha_num_max_element_row(cat_data)).isin(list3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.433054529388459"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CATEGORICAL_Unique count\n",
    "pd.Series(nunique_row(cat_data)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CATEGORICAL_out_L3_S32_F3854_class1\n",
    "# CATEGORICAL_out_L3_S32_F3854_class1           0.003434\n",
    "col_nr = lut[lut['name_cat']=='L3_S32_F3854'].col_cat.values[0].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = pd.Series(cat_data[:, 1986].todense().A1)\n",
    "d.replace(0, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp = np.zeros(d.shape)\n",
    "tmp[(d==16).values] = 1\n",
    "tmp[(d==48).values] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0034340108148109352"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CATEGORICAL_out_L3_S32_F3854_class2\n",
    "# CATEGORICAL_out_out_L3_S32_F3854_class2       0.008123\n",
    "tmp = np.zeros(d.shape)\n",
    "tmp[(d==2).values] = 2\n",
    "tmp[(d==4).values] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0081233574403990049"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
